def train_xgboost(ftr_index, random_state):

    from data_split import get_data
    import xgboost as xgb
    import pickle
    import numpy as np

    from sklearn import metrics

    # with open('../data/ftr_index.pickle', 'rb') as f_in:
    #     ftr_index = pickle.load(f_in)

    X_train, y_train, X_test, y_test = get_data(ftr_index, random_state)

    xgb_train = xgb.DMatrix(X_train, label=y_train)
    xgb_test = xgb.DMatrix(X_test, label=y_test)

    # setup parameters for xgboost
    param = {}
    # use softmax multi-class classification
    param['objective'] = 'multi:softprob'
    param['eval_metric'] = ['merror', 'mlogloss']
    param['eta'] = 0.1
    param['max_depth'] = 6
    param['silent'] = 1
    param['nthread'] = 4
    param['num_class'] = 8
    watchlist = [(xgb_train, 'train'), (xgb_test, 'test')]
    num_round = 500

    bst = xgb.train(params=param,
                    dtrain=xgb_train,
                    num_boost_round=num_round,
                    evals=watchlist,
                    maximize=False,
                    early_stopping_rounds=20)

    y_pred_prob = bst.predict(xgb_test)
    y_pred_labels = np.argmax(y_pred_prob, axis=1)

    logloss = metrics.log_loss(y_test, y_pred_prob)
    acc = metrics.accuracy_score(y_test, y_pred_labels)
    precision, recall, fscore, support = metrics.precision_recall_fscore_support(
        y_test, y_pred_labels)

    result_list = []
    result_list.append(logloss)
    result_list.append(acc)
    for i in range(8):
        result_list.append(recall[i])
        result_list.append(precision[i])
        result_list.append(fscore[i])

    return result_list
