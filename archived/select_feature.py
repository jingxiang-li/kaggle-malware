from heapq import nlargest
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction import DictVectorizer
from sklearn.preprocessing import StandardScaler
import numpy as np
import pandas as pd
import pickle


def select_k_best(k, X, y):
    clf = RandomForestClassifier(
        n_estimators=1000,
        criterion='entropy',
        n_jobs=-1,
        class_weight='balanced_subsample',
        verbose=1)
    clf.fit(X, y)
    score = clf.feature_importances_
    index = nlargest(k, range(len(score)), score.take)
    return index


# get y labels
labels = pd.read_csv(
    '/media/s_ariel/HDD_1T/Kaggle/downloads/trainLabels.csv',
    index_col=0)
labels.sort_index(inplace=True)
y = labels['Class'].as_matrix() - 1


# 1-gram and 2-gram, select top 500
# with open('./instr_freq.pickle', 'rb') as f_in:
#     gram_dict = pickle.load(f_in)

# vectorizer = DictVectorizer(dtype=np.int32)
# X = vectorizer.fit_transform(gram_dict)
# X = X[:, X.max(0).toarray()[0] > 150]

# index = select_k_best(500, X, y)
# with open('/home/s_ariel/Documents/data/gram_12.pickle', 'wb') as f_out:
#     pickle.dump(X[:, index], f_out)


# 3-gram and 4-gram, select top 1000
# with open('./gram_count.pickle', 'rb') as f_in:
#     gram_dict = pickle.load(f_in)

# vectorizer = DictVectorizer(dtype=np.int32)
# X = vectorizer.fit_transform(gram_dict)

# index = select_k_best(1000, X, y)
# with open('/home/s_ariel/Documents/data/gram_34.pickle', 'wb') as f_out:
#     pickle.dump(X[:, index], f_out)


# segment count
# with open('./seg_counter.pickle', 'rb') as f_in:
#     gram_dict = pickle.load(f_in)

# vectorizer = DictVectorizer(dtype=np.int32)
# X = vectorizer.fit_transform(gram_dict)

# index = select_k_best(250, X, y)
# with open('/home/s_ariel/Documents/data/seg.pickle', 'wb') as f_out:
#     pickle.dump(X[:, index], f_out)


# img feature
# with open('img_feature.pickle', 'rb') as f_in:
#     X = np.array(pickle.load(f_in))

# preprocesser = StandardScaler()
# X = preprocesser.fit_transform(X)
# pca = PCA(n_components=0.95)
# X_new = pca.fit_transform(X)

# with open('/home/s_ariel/Documents/data/img.pickle', 'wb') as f_out:
#     pickle.dump(X_new, f_out)


# file size
with open('./size.pickle', 'rb') as f_in:
    X = np.array(pickle.load(f_in))
X = X.swapaxes(0, 1)
X = np.int32(X)
with open('/home/s_ariel/Documents/data/size.pickle', 'wb') as f_out:
    pickle.dump(X, f_out)
